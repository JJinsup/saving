{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e254a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import QuantileTransformer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# %%\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# %%\n",
    "# 1. ë°ì´í„° ë¡œë“œ\n",
    "scenario_dir = Path(\"/home/delivery/flexric_oran/dev/data/250905/output/scenarios\")\n",
    "scenario_files = list(scenario_dir.glob(\"data_LOS*\"))\n",
    "\n",
    "scenario_info = []\n",
    "for scenario_file in scenario_files:\n",
    "    df_temp = pd.read_csv(scenario_file)\n",
    "    scenario_info.append({\n",
    "        'file': scenario_file,\n",
    "        'name': scenario_file.stem,\n",
    "        'rows': len(df_temp),\n",
    "        'ues': df_temp['imsi'].nunique()\n",
    "    })\n",
    "\n",
    "print(\"ğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ë³„ ë°ì´í„° í¬ê¸°:\")\n",
    "for info in scenario_info:\n",
    "    print(f\"  {info['name']}: {info['rows']} rows, {info['ues']} UEs\")\n",
    "\n",
    "test_scenario_name = \"data_LOS_mobrun_1_ma\"  # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì§€ì •\n",
    "test_scenario = next((info for info in scenario_info if info['name'] == test_scenario_name), None)\n",
    "\n",
    "if test_scenario is None:\n",
    "    print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ '{test_scenario_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    exit()\n",
    "\n",
    "train_scenarios = [info for info in scenario_info if info['name'] != test_scenario_name]\n",
    "\n",
    "print(f\"\\nğŸ¯ Test scenario: {test_scenario['name']} ({test_scenario['rows']} rows)\")\n",
    "print(f\"ğŸ¯ Train scenarios: {[s['name'] for s in train_scenarios]} (ì´ {len(train_scenarios)}ê°œ)\")\n",
    "\n",
    "# %%\n",
    "# 2. ìµœì  í”¼ì²˜ ì¡°í•©: timestamp í¬í•¨ (1.63m ë‹¬ì„±í•œ ì„¤ì •)\n",
    "feature_cols = [\n",
    "    \"relative_timestamp\",  # ğŸ”‘ í•µì‹¬ ì¶”ê°€ í”¼ì²˜!\n",
    "    \"serving_x\", \"serving_y\",\n",
    "    \"L3 serving SINR 3gpp_ma\",\n",
    "    \"L3 neigh SINR 3gpp 1 (convertedSinr)_ma\",\n",
    "    \"L3 neigh SINR 3gpp 2 (convertedSinr)_ma\",\n",
    "    \"L3 neigh SINR 3gpp 3 (convertedSinr)_ma\"\n",
    "]\n",
    "target_cols = [\"UE_x\", \"UE_y\"]\n",
    "\n",
    "print(f\"\\nğŸ“‹ ì‚¬ìš©í•  í”¼ì²˜: {len(feature_cols)}ê°œ\")\n",
    "for i, col in enumerate(feature_cols):\n",
    "    print(f\"  {i+1}. {col}\")\n",
    "\n",
    "# %%\n",
    "# 3. ë°ì´í„° ì¤€ë¹„\n",
    "train_X, train_y, train_imsi = [], [], []\n",
    "\n",
    "for train_info in train_scenarios:\n",
    "    print(f\"Processing train data: {train_info['name']}\")\n",
    "    df = pd.read_csv(train_info['file'])\n",
    "    df[\"imsi\"] = df[\"imsi\"].astype(\"category\").cat.codes\n",
    "    \n",
    "    for imsi_val, g in df.groupby(\"imsi\"):\n",
    "        g = g.sort_values(\"relative_timestamp\")\n",
    "        arr = g[feature_cols].to_numpy(dtype=\"float32\")\n",
    "        tgt = g[target_cols].to_numpy(dtype=\"float32\")\n",
    "        \n",
    "        for i in range(len(arr)):\n",
    "            train_X.append(arr[i])\n",
    "            train_y.append(tgt[i])\n",
    "            train_imsi.append(f\"{train_info['name']}_{imsi_val}\")\n",
    "\n",
    "test_X, test_y, test_imsi, test_timestamps = [], [], [], []\n",
    "\n",
    "print(f\"Processing test data: {test_scenario['name']}\")\n",
    "df = pd.read_csv(test_scenario['file'])\n",
    "df[\"imsi\"] = df[\"imsi\"].astype(\"category\").cat.codes\n",
    "\n",
    "for imsi_val, g in df.groupby(\"imsi\"):\n",
    "    g = g.sort_values(\"relative_timestamp\")\n",
    "    arr = g[feature_cols].to_numpy(dtype=\"float32\")\n",
    "    tgt = g[target_cols].to_numpy(dtype=\"float32\")\n",
    "    timestamps = g[\"relative_timestamp\"].to_numpy(dtype=\"float32\")\n",
    "    \n",
    "    for i in range(len(arr)):\n",
    "        test_X.append(arr[i])\n",
    "        test_y.append(tgt[i])\n",
    "        test_imsi.append(f\"{test_scenario['name']}_{imsi_val}\")\n",
    "        test_timestamps.append(timestamps[i])\n",
    "\n",
    "X_train = np.array(train_X)\n",
    "y_train = np.array(train_y)\n",
    "X_test = np.array(test_X)\n",
    "y_test = np.array(test_y)\n",
    "\n",
    "print(f\"Train ë°ì´í„°: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test ë°ì´í„°: X={X_test.shape}, y={y_test.shape}\")\n",
    "\n",
    "# %%\n",
    "# 4. ë°ì´í„°ì…‹ í´ë˜ìŠ¤\n",
    "class UEDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.targets = torch.FloatTensor(targets)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "# %%\n",
    "# 5. Timestamp ìµœì í™”ëœ MLP ëª¨ë¸\n",
    "class TimestampOptimizedMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=512, num_layers=6, output_size=2, dropout=0.1):\n",
    "        super(TimestampOptimizedMLP, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        current_size = input_size\n",
    "        \n",
    "        # ì²« ë²ˆì§¸ ë ˆì´ì–´\n",
    "        layers.append(nn.Linear(current_size, hidden_size))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "        current_size = hidden_size\n",
    "        \n",
    "        # ì¤‘ê°„ ì€ë‹‰ì¸µë“¤\n",
    "        for i in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(current_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        \n",
    "        # ì¶œë ¥ì¸µ\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Xavier ì´ˆê¸°í™”\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            torch.nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# %%\n",
    "# 6. StandarsScalerë¡œ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "scaler_X = StandardScaler()\n",
    "scaler_Y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "y_train_scaled = scaler_Y.fit_transform(y_train)\n",
    "y_test_scaled = scaler_Y.transform(y_test)\n",
    "\n",
    "print(\"âœ… ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ\")\n",
    "\n",
    "# %%\n",
    "# 7. ë°ì´í„°ë¡œë” ìƒì„± (1.63m ë‹¬ì„±í•œ ì„¤ì •)\n",
    "batch_size = 256\n",
    "train_dataset = UEDataset(X_train_scaled, y_train_scaled)\n",
    "test_dataset = UEDataset(X_test_scaled, y_test_scaled)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# %%\n",
    "# 8. ëª¨ë¸ ì´ˆê¸°í™”\n",
    "n_features = X_train.shape[1]\n",
    "model = TimestampOptimizedMLP(\n",
    "    input_size=n_features,\n",
    "    hidden_size=512,\n",
    "    num_layers=6,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"ğŸ“Š ëª¨ë¸ ì •ë³´:\")\n",
    "print(f\"  ì…ë ¥ í¬ê¸°: {n_features} í”¼ì²˜ (timestamp í¬í•¨)\")\n",
    "print(f\"  ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}\")\n",
    "\n",
    "# %%\n",
    "# 9. ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì • (1.63m ë‹¬ì„±í•œ ì„¤ì •)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=10, verbose=True\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š í›ˆë ¨ ì„¤ì •:\")\n",
    "print(f\"  ë°°ì¹˜ í¬ê¸°: {batch_size}\")\n",
    "print(f\"  ì†ì‹¤ í•¨ìˆ˜: MSELoss\")\n",
    "print(f\"  ì˜µí‹°ë§ˆì´ì €: Adam (lr=0.0005)\")\n",
    "print(f\"  ìŠ¤ì¼€ì¤„ëŸ¬: ReduceLROnPlateau\")\n",
    "\n",
    "# %%\n",
    "# 10. ìµœì í™”ëœ í›ˆë ¨ í•¨ìˆ˜\n",
    "def train_timestamp_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=300):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 20  # 1.63m ë‹¬ì„±í•œ ì„¤ì •\n",
    "    best_model_state = None\n",
    "    \n",
    "    print(\"ğŸš€ Timestamp í¬í•¨ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_train_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_train_loss = epoch_train_loss / num_batches\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in test_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item()\n",
    "                val_batches += 1\n",
    "        \n",
    "        avg_val_loss = val_loss / val_batches\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Early stopping with best model saving\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"  Early stopping at epoch {epoch+1}\")\n",
    "            if best_model_state is not None:\n",
    "                model.load_state_dict(best_model_state)\n",
    "            break\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f'  Epoch [{epoch+1:3d}/{epochs}] | Train: {avg_train_loss:.6f} | Val: {avg_val_loss:.6f} | LR: {current_lr:.6f}')\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"âœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë³µì› ì™„ë£Œ (Val Loss: {best_val_loss:.6f})\")\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "# %%\n",
    "# 11. ëª¨ë¸ í›ˆë ¨\n",
    "train_losses, val_losses = train_timestamp_model(\n",
    "    model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=300\n",
    ")\n",
    "\n",
    "# %%\n",
    "# 12. ìµœì¢… í‰ê°€\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "print(\"ğŸ” ìµœì¢… í‰ê°€ ì¤‘...\")\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_x)\n",
    "        \n",
    "        all_predictions.append(outputs.cpu().numpy())\n",
    "        all_targets.append(batch_y.cpu().numpy())\n",
    "\n",
    "predictions = np.vstack(all_predictions)\n",
    "targets = np.vstack(all_targets)\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§ ë˜ëŒë¦¬ê¸°\n",
    "predictions_unscaled = scaler_Y.inverse_transform(predictions)\n",
    "targets_unscaled = scaler_Y.inverse_transform(targets)\n",
    "\n",
    "# RMSE ê³„ì‚°\n",
    "rmse = np.sqrt(np.mean((predictions_unscaled - targets_unscaled)**2))\n",
    "\n",
    "print(f\"\\nğŸ¯ ìµœì¢… ì„±ëŠ¥:\")\n",
    "print(f\"  RMSE: {rmse:.2f}m\")\n",
    "\n",
    "# ì„±ëŠ¥ ë¹„êµ\n",
    "baseline_rmse = 12.81\n",
    "target_rmse = 1.63  # ì‹¤í—˜ì—ì„œ ë‹¬ì„±í•œ ì„±ëŠ¥\n",
    "improvement_vs_baseline = ((baseline_rmse - rmse) / baseline_rmse) * 100\n",
    "improvement_vs_target = ((target_rmse - rmse) / target_rmse) * 100\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ì„±ëŠ¥ ë¹„êµ:\")\n",
    "print(f\"  ê¸°ì¡´ (timestamp ì—†ìŒ): {baseline_rmse:.2f}m\")\n",
    "print(f\"  ëª©í‘œ (timestamp í¬í•¨): {target_rmse:.2f}m\")\n",
    "print(f\"  í˜„ì¬ ë‹¬ì„±: {rmse:.2f}m\")\n",
    "print(f\"  ê¸°ì¡´ ëŒ€ë¹„ ê°œì„ : {improvement_vs_baseline:.1f}%\")\n",
    "\n",
    "if rmse <= target_rmse * 1.1:  # 10% ì˜¤ì°¨ ë²”ìœ„ ë‚´\n",
    "    print(f\"  âœ… ëª©í‘œ ì„±ëŠ¥ ë‹¬ì„±! (ëª©í‘œ ëŒ€ë¹„ {improvement_vs_target:+.1f}%)\")\n",
    "else:\n",
    "    print(f\"  âš ï¸ ëª©í‘œ ì„±ëŠ¥ ë¯¸ë‹¬ (ëª©í‘œ ëŒ€ë¹„ {improvement_vs_target:+.1f}%)\")\n",
    "\n",
    "# %%\n",
    "# 13. ê²°ê³¼ DataFrame ìƒì„±\n",
    "results_df = pd.DataFrame({\n",
    "    'true_x': targets_unscaled[:, 0],\n",
    "    'true_y': targets_unscaled[:, 1],\n",
    "    'pred_x': predictions_unscaled[:, 0],\n",
    "    'pred_y': predictions_unscaled[:, 1],\n",
    "    'imsi': test_imsi,\n",
    "    'timestamp': test_timestamps\n",
    "})\n",
    "\n",
    "# %%\n",
    "# 14. ëª¨ë¸ ì €ì¥\n",
    "model_save_dict = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': {\n",
    "        'input_size': n_features,\n",
    "        'hidden_size': 512,\n",
    "        'num_layers': 6,\n",
    "        'dropout': 0.1,\n",
    "        'output_size': 2,\n",
    "        'features': feature_cols  # ì‚¬ìš©ëœ í”¼ì²˜ ì •ë³´ ì €ì¥\n",
    "    },\n",
    "    'scaler_X': scaler_X,\n",
    "    'scaler_Y': scaler_Y,\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'rmse': rmse,\n",
    "    'feature_importance': 'timestamp_included'\n",
    "}\n",
    "\n",
    "torch.save(model_save_dict, 'dnn_250829.pth')\n",
    "joblib.dump(scaler_X, 'dnn_250829_x.pkl')\n",
    "joblib.dump(scaler_Y, 'dnn_250829_y.pkl')\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: dnn_250829.pth\")\n",
    "\n",
    "# %%\n",
    "# 16. ìƒì„¸ ì„±ëŠ¥ í†µê³„ ì¶œë ¥\n",
    "print(f\"\\nğŸ“Š ìƒì„¸ ì„±ëŠ¥ í†µê³„ (Timestamp í¬í•¨):\")\n",
    "print(f\"  ìµœì¢… RMSE: {rmse:.2f} m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
